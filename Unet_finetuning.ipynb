{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81dc4294",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:1613: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/pytorch/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:1639: FutureWarning: RandomContrast has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "\n",
    "def define_augmentation(w, h):\n",
    "    train_transforms = A.Compose([ \n",
    "        A.Resize(width=w, height=h, p=1.0),\n",
    "        A.OneOf([\n",
    "            A.Downscale(),\n",
    "        ], p=0.5),        \n",
    "        \n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        \n",
    "        A.Affine(p=0.8),\n",
    "        \n",
    "        A.OneOf([\n",
    "            A.RandomBrightnessContrast(),\n",
    "            A.RandomBrightness(),\n",
    "            A.RandomContrast()\n",
    "        ], p=0.5),\n",
    "        \n",
    "        A.Normalize(p=1.0),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "    valid_transforms = A.Compose([ \n",
    "        A.Resize(width=w, height=h, p=1.0),\n",
    "        A.Normalize(p=1.0),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "    return train_transforms, valid_transforms\n",
    "\n",
    "\n",
    "class USDataset(Dataset):\n",
    "    def __init__(self, path, transform=None):        \n",
    "        self.path_masks = glob.glob(path)\n",
    "        self.path_images = [p.replace(\"annotations\", \"images\").replace(\"png\", \"jpg\") for p in self.path_masks]\n",
    "        self.transform = transform\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.path_images)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(self.path_images[idx], cv2.IMREAD_COLOR)\n",
    "        mask = cv2.imread(self.path_masks[idx], cv2.IMREAD_COLOR)\n",
    "        \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "        mask = rgb2mask(mask)\n",
    "        \n",
    "        transformed = self.transform(image=image, mask=mask)\n",
    "        \n",
    "        transformed_image = transformed['image']\n",
    "        transformed_mask = transformed['mask'].long()\n",
    "        \n",
    "        transoformed_image = transformed_image.permute(2,0,1).float()\n",
    "        return transformed_image, transformed_mask\n",
    "\n",
    "    \n",
    "train_transform, valid_transform = define_augmentation(512, 512)\n",
    "    \n",
    "train_dataset = USDataset('data/abdominal_US/RUS/annotations/test/*.png', transform=train_transform)\n",
    "valid_dataset = USDataset('data/abdominal_US/RUS/annotations/test/*.png', transform=valid_transform)\n",
    "\n",
    "batch_size = 4\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd6dd892",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_TO_COLOR = {\n",
    "    0: [0, 0, 0], # background \n",
    "    1: [0, 255, 0], # gallbladder\n",
    "    2: [255, 255, 0], # kidney\n",
    "    3: [0, 255, 255], # adrenals\n",
    "    4: [100, 0, 100], # liver\n",
    "    5: [0, 0, 255], # pancreas\n",
    "    6: [255, 0, 0], # vessels\n",
    "    7: [255, 0, 255], # spleen\n",
    "    8: [255, 255, 255], # bones    \n",
    "}\n",
    "\n",
    "def mask2rgb(mask):\n",
    "    rgb = np.zeros(mask.shape+(3,), dtype=np.uint8)\n",
    "    \n",
    "    for i in np.unique(mask):\n",
    "        rgb[mask==i] = LABEL_TO_COLOR[i]\n",
    "            \n",
    "    return rgb\n",
    "\n",
    "def rgb2mask(rgb):\n",
    "    mask = np.zeros((rgb.shape[0], rgb.shape[1]))\n",
    "\n",
    "    for k, v in LABEL_TO_COLOR.items():            \n",
    "        mask[np.all(rgb==v, axis=2)] = k\n",
    "        \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ed94eac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torchmetrics.functional import jaccard_index\n",
    "\n",
    "class Unet(pl.LightningModule):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super(Unet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = True\n",
    "\n",
    "        def double_conv(in_channels, out_channels):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU(inplace=True),\n",
    "            )\n",
    "\n",
    "        def down(in_channels, out_channels):\n",
    "            return nn.Sequential(\n",
    "                nn.MaxPool2d(2),\n",
    "                double_conv(in_channels, out_channels)\n",
    "            )\n",
    "\n",
    "        class up(nn.Module):\n",
    "            def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "                super().__init__()\n",
    "\n",
    "                if bilinear:\n",
    "                    self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "                else:\n",
    "                    self.up = nn.ConvTranpose2d(in_channels // 2, in_channels // 2,\n",
    "                                                kernel_size=2, stride=2)\n",
    "\n",
    "                self.conv = double_conv(in_channels, out_channels)\n",
    "\n",
    "            def forward(self, x1, x2):\n",
    "                x1 = self.up(x1)\n",
    "                \n",
    "                diffY = x2.size()[2] - x1.size()[2]\n",
    "                diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "                x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                                diffY // 2, diffY - diffY // 2])\n",
    "                x = torch.cat([x2, x1], dim=1)\n",
    "                \n",
    "                return self.conv(x)\n",
    "\n",
    "            \n",
    "        self.inc = double_conv(self.n_channels, 64)\n",
    "        \n",
    "        self.down1 = down(64, 128)\n",
    "        self.down2 = down(128, 256)\n",
    "        self.down3 = down(256, 512)\n",
    "        self.down4 = down(512, 512)\n",
    "        \n",
    "        self.up1 = up(1024, 256)\n",
    "        self.up2 = up(512, 128)\n",
    "        self.up3 = up(256, 64)\n",
    "        self.up4 = up(128, 64)\n",
    "        \n",
    "        self.out = nn.Conv2d(64, self.n_classes, kernel_size=1)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        \n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        \n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        \n",
    "        return self.out(x)\n",
    "\n",
    "    \n",
    "    def training_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        \n",
    "        loss = F.cross_entropy(y_hat, y) if self.n_classes > 1 else \\\n",
    "            F.binary_cross_entropy_with_logits(y_hat, y)\n",
    "        \n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    \n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        \n",
    "        loss = F.cross_entropy(y_hat, y) if self.n_classes > 1 else \\\n",
    "            F.binary_cross_entropy_with_logits(y_hat, y)\n",
    "        \n",
    "        self.log('valid_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "    \n",
    "    def test_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        \n",
    "        loss = F.cross_entropy(y_hat, y) if self.n_classes > 1 else \\\n",
    "            F.binary_cross_entropy_with_logits(y_hat, y)\n",
    "        \n",
    "        pred = F.softmax(y_hat, dim=1)\n",
    "        pred = torch.argmax(pred, dim=1)\n",
    "        \n",
    "        pred[pred != 4] = 0\n",
    "        pred[pred == 4] = 1\n",
    "        \n",
    "        y[y != 4] = 0\n",
    "        y[y == 4] = 1\n",
    "        \n",
    "        binary_iou = jaccard_index(pred, y, num_classes=2)\n",
    "        \n",
    "        self.log('test_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('test_binary_iou', binary_iou, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=2e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=25)\n",
    "        \n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "    \n",
    "    \n",
    "callbacks = [\n",
    "    ModelCheckpoint(monitor='valid_loss', save_top_k=3, dirpath='weights/Unet_finetuning', filename='Unet-{epoch:03d}-{valid_loss:.4f}'),\n",
    "]\n",
    "\n",
    "unet = Unet(3, 9)\n",
    "ckpt_fname = \"Unet-epoch=028-valid_loss=0.2673.ckpt\"\n",
    "unet = unet.load_from_checkpoint(\"weights/Unet_pretraining/\" + ckpt_fname, n_channels=3, n_classes=9)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=25, \n",
    "                     gpus=[1], \n",
    "                     enable_progress_bar=True, \n",
    "                     callbacks=callbacks, \n",
    "                     precision=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f77350b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# trainer.fit(unet, train_dataloader, valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba8ddb88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a4017c373f43be95141aaac9f4bc12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     test_binary_iou        0.7147191762924194\n",
      "        test_loss           0.19659487903118134\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.19659487903118134, 'test_binary_iou': 0.7147191762924194}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_fname = \"Unet-epoch=024-valid_loss=0.1967.ckpt\"\n",
    "unet = unet.load_from_checkpoint(\"weights/Unet_finetuning/\" + ckpt_fname, n_channels=3, n_classes=9)\n",
    "\n",
    "trainer.test(unet, valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2d297a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
