{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63ed5e1a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>kPa_fib</th>\n",
       "      <th>target</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00266195</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0</td>\n",
       "      <td>data/roi/00266195-0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00266195</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0</td>\n",
       "      <td>data/roi/00266195-1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00266195</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0</td>\n",
       "      <td>data/roi/00266195-10.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00266195</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0</td>\n",
       "      <td>data/roi/00266195-11.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00266195</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0</td>\n",
       "      <td>data/roi/00266195-12.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  kPa_fib  target                image_path\n",
       "0  00266195      3.8       0   data/roi/00266195-0.jpg\n",
       "1  00266195      3.8       0   data/roi/00266195-1.jpg\n",
       "2  00266195      3.8       0  data/roi/00266195-10.jpg\n",
       "3  00266195      3.8       0  data/roi/00266195-11.jpg\n",
       "4  00266195      3.8       0  data/roi/00266195-12.jpg"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import timm\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torchmetrics.functional import mean_squared_error, mean_absolute_error\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "df = pd.read_excel(\"data/US_fibrosis_stage_dataset.xlsx\", engine=\"openpyxl\")\n",
    "df = df.loc[(df.AST < 100) | (df.ALT < 100)].reset_index(drop=True)\n",
    "df = df.loc[:, [\"ID\", \"kPa_fib\"]].dropna().reset_index(drop=True)\n",
    "df.kPa_fib = df.kPa_fib.map(lambda x: 25 if x >= 25 else x)\n",
    "\n",
    "def generate_target(x):\n",
    "    if x > 12:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "df.loc[:, \"target\"] = df.kPa_fib.map(generate_target)\n",
    "df.ID = df.ID.map(lambda x: str(x).zfill(8))\n",
    "\n",
    "flist = os.listdir(\"data/roi/\")\n",
    "id_list = list(map(lambda x: x.split(\"_\")[0].zfill(8), flist))\n",
    "\n",
    "image_df = pd.DataFrame(glob.glob(os.path.join(\"data\", \"roi\", \"*.jpg\")), columns=[\"image_path\"])\n",
    "image_df.loc[:, \"ID\"] = image_df.image_path.map(lambda x: x.split(\"/\")[-1].split(\"-\")[0])\n",
    "\n",
    "df = pd.merge(df, image_df, on=\"ID\", how=\"inner\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d2528d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  902\n",
      "Valid:  101\n",
      "Test:  177\n"
     ]
    }
   ],
   "source": [
    "ids = df.loc[:, [\"ID\", \"target\"]].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "train_id, test_id = train_test_split(ids, stratify=ids.target, test_size=0.15, random_state=42)\n",
    "train_id = train_id.reset_index(drop=True)\n",
    "\n",
    "train_id, valid_id = train_test_split(train_id, stratify=train_id.target, test_size=0.1, random_state=42)\n",
    "train_id = train_id.ID\n",
    "valid_id = valid_id.ID\n",
    "test_id = test_id.ID\n",
    "\n",
    "train_df = df[df.ID.isin(train_id)].reset_index(drop=True)\n",
    "valid_df = df[df.ID.isin(valid_id)].reset_index(drop=True)\n",
    "test_df = df[df.ID.isin(test_id)].reset_index(drop=True)\n",
    "\n",
    "print(\"Train: \", len(train_df.ID.drop_duplicates()))\n",
    "print(\"Valid: \", len(valid_df.ID.drop_duplicates()))\n",
    "print(\"Test: \", len(test_df.ID.drop_duplicates()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03870406",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:1613: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/pytorch/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:1639: FutureWarning: RandomContrast has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from typing import Callable\n",
    "\n",
    "class ImbalancedDatasetSampler(torch.utils.data.sampler.Sampler):\n",
    "    \"\"\"Samples elements randomly from a given list of indices for imbalanced dataset\n",
    "    Arguments:\n",
    "        indices: a list of indices\n",
    "        num_samples: number of samples to draw\n",
    "        callback_get_label: a callback-like function which takes two arguments - dataset and index\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset,\n",
    "        labels: list = None,\n",
    "        indices: list = None,\n",
    "        num_samples: int = None,\n",
    "        callback_get_label: Callable = None,\n",
    "    ):\n",
    "        # if indices is not provided, all elements in the dataset will be considered\n",
    "        self.indices = list(range(len(dataset))) if indices is None else indices\n",
    "\n",
    "        # define custom callback\n",
    "        self.callback_get_label = dataset.df.target\n",
    "\n",
    "        # if num_samples is not provided, draw `len(indices)` samples in each iteration\n",
    "        self.num_samples = len(self.indices) if num_samples is None else num_samples\n",
    "\n",
    "        # distribution of classes in the dataset\n",
    "        df = pd.DataFrame()\n",
    "        df[\"label\"] = self._get_labels(dataset) if labels is None else labels\n",
    "        df.index = self.indices\n",
    "        df = df.sort_index()\n",
    "\n",
    "        label_to_count = df[\"label\"].value_counts()\n",
    "\n",
    "        weights = 1.0 / label_to_count[df[\"label\"]]\n",
    "\n",
    "        self.weights = torch.DoubleTensor(weights.to_list())\n",
    "\n",
    "    def __iter__(self):\n",
    "        return (self.indices[i] for i in torch.multinomial(self.weights, self.num_samples, replacement=True))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    \n",
    "\n",
    "def define_augmentation(w, h):\n",
    "    train_transforms = A.Compose([ \n",
    "        A.Resize(width=w, height=h, p=1.0),\n",
    "        A.OneOf([\n",
    "            A.Downscale(),\n",
    "        ], p=0.5),        \n",
    "        \n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        \n",
    "        A.Affine(p=0.8),\n",
    "        \n",
    "        A.OneOf([\n",
    "            A.RandomBrightnessContrast(),\n",
    "            A.RandomBrightness(),\n",
    "            A.RandomContrast()\n",
    "        ], p=0.5),\n",
    "        \n",
    "        A.Normalize(p=1.0),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "    valid_transforms = A.Compose([ \n",
    "        A.Resize(width=w, height=h, p=1.0),\n",
    "        A.Normalize(p=1.0),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "    return train_transforms, valid_transforms\n",
    "\n",
    "\n",
    "class SonographyDataset(Dataset):\n",
    "    def __init__(self, df, transform, train_mode=False):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.train_mode = train_mode\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(self.df.loc[idx, \"image_path\"])\n",
    "        image = self.transform(image=image)\n",
    "        \n",
    "        y = self.df.loc[idx, \"kPa_fib\"]\n",
    "#         if self.train_mode:\n",
    "#             y += np.log(np.random.rand(1)[0])\n",
    "        \n",
    "        return image['image'], torch.tensor(y).log().float()\n",
    "    \n",
    "    \n",
    "train_transform, valid_transform = define_augmentation(w=224, h=224)\n",
    "\n",
    "train_dataset = SonographyDataset(train_df, train_transform, train_mode=True)\n",
    "valid_dataset = SonographyDataset(valid_df, valid_transform)\n",
    "test_dataset = SonographyDataset(test_df, valid_transform)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, \n",
    "                              num_workers=16, prefetch_factor=10,\n",
    "                              sampler=ImbalancedDatasetSampler(train_dataset, labels=train_dataset.df.target),\n",
    "                              pin_memory=True)\n",
    "\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, \n",
    "                              num_workers=16, prefetch_factor=10,\n",
    "                              pin_memory=True)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, \n",
    "                              num_workers=16, prefetch_factor=10,\n",
    "                              pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dce66461",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:429: LightningDeprecationWarning: Setting `Trainer(gpus=[1])` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=[1])` instead.\n",
      "  rank_zero_deprecation(\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "class KpaPredictor(pl.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    \n",
    "    def step(self, batch):\n",
    "        # x: image, y: kpa\n",
    "        x, y = batch\n",
    "        preds = torch.squeeze(self(x), -1)\n",
    "        \n",
    "        loss = F.l1_loss(preds, y)\n",
    "        mse = torch.sqrt(mean_squared_error(preds, y))\n",
    "        \n",
    "        return preds, loss, mse\n",
    "    \n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        _, loss, rmse = self.step(batch)\n",
    "        \n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_rmse', rmse, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        _, loss, rmse = self.step(batch)\n",
    "        \n",
    "        self.log('valid_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('valid_rmse', rmse, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        _, loss, rmse = self.step(batch)\n",
    "        \n",
    "        self.log('test_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('test_rmse', rmse, on_step=False, on_epoch=True, prog_bar=True)\n",
    "    \n",
    "    \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        preds, _, _ = self.step(batch)\n",
    "        \n",
    "        return preds\n",
    "\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=5e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "        \n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "    \n",
    "    \n",
    "    def lr_scheduler_step(self, scheduler, optimizer_idx, metric):\n",
    "        scheduler.step(epoch=self.current_epoch)\n",
    "\n",
    "    \n",
    "    \n",
    "callbacks = [\n",
    "    ModelCheckpoint(monitor='valid_loss', save_top_k=3, dirpath='weights/ResNet152_regression', filename='kpa_predictor-{epoch:03d}-{valid_loss:.4f}-{valid_rmse:.4f}'),\n",
    "]\n",
    "\n",
    "\n",
    "model = timm.create_model(\"resnet152\", num_classes=1, pretrained=True)\n",
    "kpa_predictor = KpaPredictor(model)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=50, gpus=[1], \n",
    "                     enable_progress_bar=True, \n",
    "                     callbacks=callbacks, precision=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed583f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:613: UserWarning: Checkpoint directory /home/ubuntu/Workspace/UltrasonographyImageAnalysis/weights/ResNet152_regression exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | model | ResNet | 58.1 M\n",
      "---------------------------------\n",
      "58.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "58.1 M    Total params\n",
      "116.292   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c02558f98c24b88862d31d1a7338936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(kpa_predictor, train_dataloader, valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30526671",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e6d157b75b1417ea96debe0f633190c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.4280899465084076\n",
      "        test_rmse           0.5596672296524048\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.4280899465084076, 'test_rmse': 0.5596672296524048}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_fname = \"kpa_predictor-epoch=025-valid_loss=0.4188-valid_rmse=0.5472.ckpt\"\n",
    "kpa_predictor = kpa_predictor.load_from_checkpoint(\"weights/ResNet152_regression/\" + ckpt_fname, model=model)\n",
    "\n",
    "trainer.test(kpa_predictor, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5902d366",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>kPa_fib</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>age</th>\n",
       "      <th>AST</th>\n",
       "      <th>ALT</th>\n",
       "      <th>PLT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00883439</td>\n",
       "      <td>7.3</td>\n",
       "      <td>20.191383</td>\n",
       "      <td>5.098398</td>\n",
       "      <td>4.340386</td>\n",
       "      <td>59</td>\n",
       "      <td>42.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>158.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01034390</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.011755</td>\n",
       "      <td>5.820227</td>\n",
       "      <td>4.723373</td>\n",
       "      <td>72</td>\n",
       "      <td>25.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>139.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01062934</td>\n",
       "      <td>11.7</td>\n",
       "      <td>4.694145</td>\n",
       "      <td>4.607368</td>\n",
       "      <td>4.416852</td>\n",
       "      <td>72</td>\n",
       "      <td>34.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>139.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01067391</td>\n",
       "      <td>8.9</td>\n",
       "      <td>9.413785</td>\n",
       "      <td>8.260871</td>\n",
       "      <td>5.150177</td>\n",
       "      <td>62</td>\n",
       "      <td>55.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>259.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01092354</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.840446</td>\n",
       "      <td>4.682412</td>\n",
       "      <td>4.656144</td>\n",
       "      <td>48</td>\n",
       "      <td>22.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>01131003</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6.161881</td>\n",
       "      <td>4.332696</td>\n",
       "      <td>4.260494</td>\n",
       "      <td>59</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>236.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>01166636</td>\n",
       "      <td>10.7</td>\n",
       "      <td>8.237950</td>\n",
       "      <td>5.574651</td>\n",
       "      <td>4.677879</td>\n",
       "      <td>65</td>\n",
       "      <td>53.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>01168622</td>\n",
       "      <td>7.1</td>\n",
       "      <td>4.900640</td>\n",
       "      <td>4.894070</td>\n",
       "      <td>4.821332</td>\n",
       "      <td>75</td>\n",
       "      <td>26.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>01191410</td>\n",
       "      <td>10.4</td>\n",
       "      <td>5.126828</td>\n",
       "      <td>4.716825</td>\n",
       "      <td>4.135880</td>\n",
       "      <td>62</td>\n",
       "      <td>33.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>01193976</td>\n",
       "      <td>4.4</td>\n",
       "      <td>9.864240</td>\n",
       "      <td>4.744425</td>\n",
       "      <td>4.319278</td>\n",
       "      <td>52</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>01317734</td>\n",
       "      <td>5.6</td>\n",
       "      <td>5.974110</td>\n",
       "      <td>5.915056</td>\n",
       "      <td>4.214256</td>\n",
       "      <td>77</td>\n",
       "      <td>29.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>01536186</td>\n",
       "      <td>5.6</td>\n",
       "      <td>6.195631</td>\n",
       "      <td>4.626678</td>\n",
       "      <td>4.109561</td>\n",
       "      <td>64</td>\n",
       "      <td>52.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>269.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>01557299</td>\n",
       "      <td>4.8</td>\n",
       "      <td>11.164334</td>\n",
       "      <td>5.028321</td>\n",
       "      <td>4.336679</td>\n",
       "      <td>41</td>\n",
       "      <td>44.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>347.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>01568222</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.566766</td>\n",
       "      <td>5.146636</td>\n",
       "      <td>4.754496</td>\n",
       "      <td>45</td>\n",
       "      <td>23.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>277.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>01583287</td>\n",
       "      <td>10.7</td>\n",
       "      <td>5.501615</td>\n",
       "      <td>4.803109</td>\n",
       "      <td>4.731908</td>\n",
       "      <td>68</td>\n",
       "      <td>27.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>01684232</td>\n",
       "      <td>17.3</td>\n",
       "      <td>5.207759</td>\n",
       "      <td>4.581818</td>\n",
       "      <td>4.360296</td>\n",
       "      <td>23</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>01740337</td>\n",
       "      <td>25.0</td>\n",
       "      <td>22.592934</td>\n",
       "      <td>21.112984</td>\n",
       "      <td>20.246376</td>\n",
       "      <td>50</td>\n",
       "      <td>179.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>447.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>01753435</td>\n",
       "      <td>5.4</td>\n",
       "      <td>6.231522</td>\n",
       "      <td>5.210438</td>\n",
       "      <td>4.728986</td>\n",
       "      <td>54</td>\n",
       "      <td>28.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>01755261</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.903232</td>\n",
       "      <td>4.634765</td>\n",
       "      <td>4.188663</td>\n",
       "      <td>61</td>\n",
       "      <td>34.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>248.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>01764747</td>\n",
       "      <td>4.7</td>\n",
       "      <td>6.544219</td>\n",
       "      <td>5.928584</td>\n",
       "      <td>5.778193</td>\n",
       "      <td>69</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>01799507</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.443126</td>\n",
       "      <td>5.264175</td>\n",
       "      <td>4.964019</td>\n",
       "      <td>61</td>\n",
       "      <td>60.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>01827041</td>\n",
       "      <td>6.4</td>\n",
       "      <td>4.825082</td>\n",
       "      <td>4.746237</td>\n",
       "      <td>4.596008</td>\n",
       "      <td>61</td>\n",
       "      <td>31.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>01844554</td>\n",
       "      <td>25.0</td>\n",
       "      <td>8.098830</td>\n",
       "      <td>6.968850</td>\n",
       "      <td>4.010088</td>\n",
       "      <td>58</td>\n",
       "      <td>27.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>01861581</td>\n",
       "      <td>16.8</td>\n",
       "      <td>5.089416</td>\n",
       "      <td>4.864395</td>\n",
       "      <td>4.796148</td>\n",
       "      <td>79</td>\n",
       "      <td>50.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>01866912</td>\n",
       "      <td>11.7</td>\n",
       "      <td>4.933576</td>\n",
       "      <td>4.791234</td>\n",
       "      <td>4.734096</td>\n",
       "      <td>61</td>\n",
       "      <td>22.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>01874709</td>\n",
       "      <td>4.5</td>\n",
       "      <td>19.610909</td>\n",
       "      <td>10.871704</td>\n",
       "      <td>7.728452</td>\n",
       "      <td>65</td>\n",
       "      <td>35.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>01938468</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.264719</td>\n",
       "      <td>5.258928</td>\n",
       "      <td>5.196491</td>\n",
       "      <td>80</td>\n",
       "      <td>26.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>01963852</td>\n",
       "      <td>3.3</td>\n",
       "      <td>8.373103</td>\n",
       "      <td>4.731417</td>\n",
       "      <td>4.457922</td>\n",
       "      <td>54</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>212.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>01994679</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.912719</td>\n",
       "      <td>4.573165</td>\n",
       "      <td>4.251473</td>\n",
       "      <td>81</td>\n",
       "      <td>64.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>02009493</td>\n",
       "      <td>6.8</td>\n",
       "      <td>14.746851</td>\n",
       "      <td>5.089455</td>\n",
       "      <td>4.466280</td>\n",
       "      <td>24</td>\n",
       "      <td>52.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>02095112</td>\n",
       "      <td>11.6</td>\n",
       "      <td>10.153521</td>\n",
       "      <td>6.308383</td>\n",
       "      <td>4.281835</td>\n",
       "      <td>16</td>\n",
       "      <td>63.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>279.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>02123768</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6.416714</td>\n",
       "      <td>4.779366</td>\n",
       "      <td>4.097713</td>\n",
       "      <td>39</td>\n",
       "      <td>22.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>02130225</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.383813</td>\n",
       "      <td>3.980142</td>\n",
       "      <td>3.894099</td>\n",
       "      <td>52</td>\n",
       "      <td>40.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>241.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>02142938</td>\n",
       "      <td>5.3</td>\n",
       "      <td>6.396674</td>\n",
       "      <td>5.440385</td>\n",
       "      <td>5.242875</td>\n",
       "      <td>71</td>\n",
       "      <td>26.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>02158367</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5.508943</td>\n",
       "      <td>5.213130</td>\n",
       "      <td>4.559316</td>\n",
       "      <td>64</td>\n",
       "      <td>36.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>02181905</td>\n",
       "      <td>12.6</td>\n",
       "      <td>7.405045</td>\n",
       "      <td>5.975339</td>\n",
       "      <td>5.238993</td>\n",
       "      <td>50</td>\n",
       "      <td>24.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>02186480</td>\n",
       "      <td>6.2</td>\n",
       "      <td>9.126216</td>\n",
       "      <td>5.149021</td>\n",
       "      <td>4.160892</td>\n",
       "      <td>53</td>\n",
       "      <td>26.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>02186930</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.264870</td>\n",
       "      <td>5.104005</td>\n",
       "      <td>4.907113</td>\n",
       "      <td>56</td>\n",
       "      <td>39.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>243.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>02187836</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.001313</td>\n",
       "      <td>5.861877</td>\n",
       "      <td>4.910685</td>\n",
       "      <td>66</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>02190955</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.870945</td>\n",
       "      <td>5.310955</td>\n",
       "      <td>4.030744</td>\n",
       "      <td>70</td>\n",
       "      <td>21.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>149.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  kPa_fib         v1         v2         v3  age    AST    ALT  \\\n",
       "0   00883439      7.3  20.191383   5.098398   4.340386   59   42.0   22.0   \n",
       "1   01034390      5.1   6.011755   5.820227   4.723373   72   25.0   18.0   \n",
       "2   01062934     11.7   4.694145   4.607368   4.416852   72   34.0   21.0   \n",
       "3   01067391      8.9   9.413785   8.260871   5.150177   62   55.0   47.0   \n",
       "4   01092354      3.3   4.840446   4.682412   4.656144   48   22.0   13.0   \n",
       "5   01131003      5.8   6.161881   4.332696   4.260494   59   22.0   12.0   \n",
       "6   01166636     10.7   8.237950   5.574651   4.677879   65   53.0   13.0   \n",
       "7   01168622      7.1   4.900640   4.894070   4.821332   75   26.0   11.0   \n",
       "8   01191410     10.4   5.126828   4.716825   4.135880   62   33.0   28.0   \n",
       "9   01193976      4.4   9.864240   4.744425   4.319278   52   26.0   24.0   \n",
       "10  01317734      5.6   5.974110   5.915056   4.214256   77   29.0   13.0   \n",
       "11  01536186      5.6   6.195631   4.626678   4.109561   64   52.0   33.0   \n",
       "12  01557299      4.8  11.164334   5.028321   4.336679   41   44.0   12.0   \n",
       "13  01568222      5.3   5.566766   5.146636   4.754496   45   23.0   12.0   \n",
       "14  01583287     10.7   5.501615   4.803109   4.731908   68   27.0   15.0   \n",
       "15  01684232     17.3   5.207759   4.581818   4.360296   23   26.0    7.0   \n",
       "16  01740337     25.0  22.592934  21.112984  20.246376   50  179.0   11.0   \n",
       "17  01753435      5.4   6.231522   5.210438   4.728986   54   28.0   19.0   \n",
       "18  01755261      4.3   4.903232   4.634765   4.188663   61   34.0   15.0   \n",
       "19  01764747      4.7   6.544219   5.928584   5.778193   69   26.0   27.0   \n",
       "20  01799507      4.0   5.443126   5.264175   4.964019   61   60.0   61.0   \n",
       "21  01827041      6.4   4.825082   4.746237   4.596008   61   31.0   34.0   \n",
       "22  01844554     25.0   8.098830   6.968850   4.010088   58   27.0   23.0   \n",
       "23  01861581     16.8   5.089416   4.864395   4.796148   79   50.0   42.0   \n",
       "24  01866912     11.7   4.933576   4.791234   4.734096   61   22.0   18.0   \n",
       "25  01874709      4.5  19.610909  10.871704   7.728452   65   35.0   28.0   \n",
       "26  01938468      5.5   5.264719   5.258928   5.196491   80   26.0   15.0   \n",
       "27  01963852      3.3   8.373103   4.731417   4.457922   54   26.0   24.0   \n",
       "28  01994679     12.0   6.912719   4.573165   4.251473   81   64.0   59.0   \n",
       "29  02009493      6.8  14.746851   5.089455   4.466280   24   52.0   50.0   \n",
       "30  02095112     11.6  10.153521   6.308383   4.281835   16   63.0   66.0   \n",
       "31  02123768      3.6   6.416714   4.779366   4.097713   39   22.0   14.0   \n",
       "32  02130225      5.8   5.383813   3.980142   3.894099   52   40.0  131.0   \n",
       "33  02142938      5.3   6.396674   5.440385   5.242875   71   26.0   13.0   \n",
       "34  02158367      5.7   5.508943   5.213130   4.559316   64   36.0   23.0   \n",
       "35  02181905     12.6   7.405045   5.975339   5.238993   50   24.0   28.0   \n",
       "36  02186480      6.2   9.126216   5.149021   4.160892   53   26.0   13.0   \n",
       "37  02186930      5.2   5.264870   5.104005   4.907113   56   39.0   14.0   \n",
       "38  02187836      7.0   7.001313   5.861877   4.910685   66   18.0    9.0   \n",
       "39  02190955      3.4   5.870945   5.310955   4.030744   70   21.0   12.0   \n",
       "\n",
       "      PLT  \n",
       "0   158.0  \n",
       "1   139.0  \n",
       "2   139.0  \n",
       "3   259.0  \n",
       "4   199.0  \n",
       "5   236.0  \n",
       "6    63.0  \n",
       "7   205.0  \n",
       "8   153.0  \n",
       "9   180.0  \n",
       "10  147.0  \n",
       "11  269.0  \n",
       "12  347.0  \n",
       "13  277.0  \n",
       "14  180.0  \n",
       "15   97.0  \n",
       "16  447.0  \n",
       "17  288.0  \n",
       "18  248.0  \n",
       "19  118.0  \n",
       "20  182.0  \n",
       "21  219.0  \n",
       "22  141.0  \n",
       "23  125.0  \n",
       "24   76.0  \n",
       "25  170.0  \n",
       "26  231.0  \n",
       "27  212.0  \n",
       "28  143.0  \n",
       "29  142.0  \n",
       "30  279.0  \n",
       "31  199.0  \n",
       "32  241.0  \n",
       "33  195.0  \n",
       "34   72.0  \n",
       "35  199.0  \n",
       "36  219.0  \n",
       "37  243.0  \n",
       "38  137.0  \n",
       "39  149.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class PredictDataset(Dataset):\n",
    "    def __init__(self, df, transform):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        ID = self.df.loc[idx, \"ID\"]\n",
    "        fname = self.df.loc[idx, \"image_path\"]\n",
    "        \n",
    "        image = cv2.imread(self.df.loc[idx, \"image_path\"])\n",
    "        image = self.transform(image=image)\n",
    "        \n",
    "        y = self.df.loc[idx, \"kPa_fib\"]\n",
    "        \n",
    "        return image['image'], torch.tensor(y).log().float(), ID, fname\n",
    "    \n",
    "predict_df = pd.concat([valid_df, test_df], axis=0).reset_index(drop=True)\n",
    "    \n",
    "predict_dataset = PredictDataset(predict_df, valid_transform)\n",
    "predict_dataloader = DataLoader(predict_dataset, batch_size=1)\n",
    "\n",
    "results = []\n",
    "\n",
    "kpa_predictor.model.eval()\n",
    "kpa_predictor.model.to(\"cuda\")\n",
    "\n",
    "for batch in predict_dataloader:\n",
    "    image, y, ID, fname = batch\n",
    "    \n",
    "    pred = kpa_predictor(image.to(\"cuda\"))\n",
    "    results.append([ID[0], np.exp(pred.detach().to(\"cpu\").numpy()[0][0])])\n",
    "    \n",
    "results = pd.DataFrame(results, columns=['ID', 'pred'])\n",
    "results = results.groupby(\"ID\").head(3).sort_values([\"ID\", \"pred\"], ascending=False).groupby(\"ID\").agg(list).reset_index()\n",
    "results = pd.concat([results['ID'], pd.DataFrame(results['pred'].tolist(), columns=['v1', 'v2', 'v3'])], axis=1)\n",
    "\n",
    "df = pd.read_excel(\"data/US_fibrosis_stage_dataset.xlsx\", engine=\"openpyxl\")\n",
    "df = df.loc[:, [\"ID\", \"age\", \"AST\", \"ALT\", \"PLT\"]]\n",
    "df.ID = df.ID.map(lambda x: str(x).zfill(8))\n",
    "\n",
    "predict_df = pd.merge(predict_df, df, on=\"ID\", how=\"left\")\n",
    "predict_df = pd.merge(predict_df, results, on=\"ID\", how=\"left\")\n",
    "predict_df = predict_df.loc[:, [\"ID\", \"kPa_fib\", \"v1\", \"v2\", \"v3\", \"age\", \"AST\", \"ALT\", \"PLT\"]]\n",
    "predict_df = predict_df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "predict_df.head(40)\n",
    "\n",
    "# predict_df.to_csv(\"data/fibroscan_predict_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e32c3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df.to_csv(\"data/fibroscan_predict_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e36837b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>kPa_mre</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00008960</td>\n",
       "      <td>4.34</td>\n",
       "      <td>data/roi_sampled/00008960-6.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00008960</td>\n",
       "      <td>4.34</td>\n",
       "      <td>data/roi_sampled/00008960-0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00008960</td>\n",
       "      <td>4.34</td>\n",
       "      <td>data/roi_sampled/00008960-1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00008960</td>\n",
       "      <td>4.34</td>\n",
       "      <td>data/roi_sampled/00008960-10.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00008960</td>\n",
       "      <td>4.34</td>\n",
       "      <td>data/roi_sampled/00008960-11.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  kPa_mre                        image_path\n",
       "0  00008960     4.34   data/roi_sampled/00008960-6.jpg\n",
       "1  00008960     4.34   data/roi_sampled/00008960-0.jpg\n",
       "2  00008960     4.34   data/roi_sampled/00008960-1.jpg\n",
       "3  00008960     4.34  data/roi_sampled/00008960-10.jpg\n",
       "4  00008960     4.34  data/roi_sampled/00008960-11.jpg"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mre_df = pd.read_excel(\"data/US_fibrosis_stage_dataset.xlsx\", engine=\"openpyxl\")\n",
    "mre_df = mre_df.loc[:, [\"ID\", \"kPa_mre\"]].dropna().reset_index(drop=True)\n",
    "mre_df.ID = mre_df.ID.map(lambda x: str(x).zfill(8))\n",
    "flist = os.listdir(\"data/roi_sampled/\")\n",
    "id_list = list(map(lambda x: x.split(\"_\")[0].zfill(8), flist))\n",
    "\n",
    "image_df = pd.DataFrame(glob.glob(os.path.join(\"data\", \"roi_sampled\", \"*.jpg\")), columns=[\"image_path\"])\n",
    "image_df.loc[:, \"ID\"] = image_df.image_path.map(lambda x: x.split(\"/\")[-1].split(\"-\")[0])\n",
    "\n",
    "mre_df = pd.merge(mre_df, image_df, on=\"ID\", how=\"inner\")\n",
    "mre_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4fa935f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictDataset(Dataset):\n",
    "    def __init__(self, df, transform):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        ID = self.df.loc[idx, \"ID\"]\n",
    "        fname = self.df.loc[idx, \"image_path\"]\n",
    "        \n",
    "        image = cv2.imread(self.df.loc[idx, \"image_path\"])\n",
    "        image = self.transform(image=image)\n",
    "        \n",
    "        y = self.df.loc[idx, \"kPa_mre\"]\n",
    "        \n",
    "        return image['image'], torch.tensor(y).log().float(), ID, fname\n",
    "\n",
    "mre_dataset = PredictDataset(mre_df, valid_transform)\n",
    "mre_dataloader = DataLoader(mre_dataset, batch_size=1)\n",
    "\n",
    "results = []\n",
    "\n",
    "kpa_predictor.model.eval()\n",
    "kpa_predictor.model.to(\"cuda\")\n",
    "\n",
    "for batch in mre_dataloader:\n",
    "    image, y, ID, fname = batch\n",
    "    \n",
    "    pred = kpa_predictor(image.to(\"cuda\"))\n",
    "    results.append([ID[0], np.exp(pred.detach().to(\"cpu\").numpy()[0][0])])\n",
    "    \n",
    "results = pd.DataFrame(results, columns=['ID', 'pred'])\n",
    "results = results.groupby(\"ID\").head(3).sort_values([\"ID\", \"pred\"], ascending=False).groupby(\"ID\").agg(list).reset_index()\n",
    "results = pd.concat([results['ID'], pd.DataFrame(results['pred'].tolist(), columns=['v1', 'v2', 'v3'])], axis=1)\n",
    "\n",
    "df = pd.read_excel(\"data/US_fibrosis_stage_dataset.xlsx\", engine=\"openpyxl\")\n",
    "df = df.loc[:, [\"ID\", \"age\", \"AST\", \"ALT\", \"PLT\"]]\n",
    "df.ID = df.ID.map(lambda x: str(x).zfill(8))\n",
    "\n",
    "mre_df = pd.merge(mre_df, df, on=\"ID\", how=\"left\")\n",
    "mre_df = pd.merge(mre_df, results, on=\"ID\", how=\"left\")\n",
    "mre_df = mre_df.loc[:, [\"ID\", \"kPa_mre\", \"v1\", \"v2\", \"v3\", \"age\", \"AST\", \"ALT\", \"PLT\"]]\n",
    "mre_df = mre_df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "mre_df.to_csv(\"data/mre_predict_df.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ef6424",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
